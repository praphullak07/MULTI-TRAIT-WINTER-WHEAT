{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14790 entries, 0 to 14789\n",
      "Columns: 291 entries, SNPs to WH1284\n",
      "dtypes: float64(3), int64(1), object(287)\n",
      "memory usage: 32.8+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 281 entries, 0 to 280\n",
      "Data columns (total 32 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Genotype             280 non-null    object \n",
      " 1   DH_Dharwad           280 non-null    float64\n",
      " 2   DH_IARI-DELHI        280 non-null    float64\n",
      " 3   DH_IARI-Jharkhand    280 non-null    float64\n",
      " 4   DH_KARNAL            280 non-null    float64\n",
      " 5   DH_Pooled            281 non-null    float64\n",
      " 6   GFD_Dharwad          280 non-null    float64\n",
      " 7   GFD_IARI-Delhi       280 non-null    float64\n",
      " 8   GFD_IARI-Jharkhand   280 non-null    float64\n",
      " 9   GFD_Karnal           280 non-null    float64\n",
      " 10  GFD_Pooled           281 non-null    float64\n",
      " 11  GNPS_Dharwad         280 non-null    float64\n",
      " 12  GNPS_IARI-Jharkhand  280 non-null    float64\n",
      " 13  GNPS_Pooled          281 non-null    float64\n",
      " 14  GWPS_Dharwad         280 non-null    float64\n",
      " 15  GWPS_IARI-Delhi      280 non-null    float64\n",
      " 16  GWPS_IARI-Jharkhand  280 non-null    float64\n",
      " 17  GWPS_Karnal          280 non-null    float64\n",
      " 18  GWPS_Ludhiana        280 non-null    float64\n",
      " 19  GWPS_Pooled          280 non-null    float64\n",
      " 20  PH_Dharwad           280 non-null    float64\n",
      " 21  PH_IARI-Delhi        280 non-null    float64\n",
      " 22  PH_IARI-Jharkhand    280 non-null    float64\n",
      " 23  PH_Karnal            280 non-null    float64\n",
      " 24  PH_Ludhiana          280 non-null    float64\n",
      " 25  PH_Pooled            280 non-null    float64\n",
      " 26  GY_Dharwad           280 non-null    float64\n",
      " 27  GY_IARI-Delhi        280 non-null    float64\n",
      " 28  GY_IARI-JKD          280 non-null    float64\n",
      " 29  GY_Karnal            280 non-null    float64\n",
      " 30  GY_Ludhiana          280 non-null    float64\n",
      " 31  GY_Pooled            281 non-null    float64\n",
      "dtypes: float64(31), object(1)\n",
      "memory usage: 70.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SNPs          0\n",
       "alleles       0\n",
       "Chrom         0\n",
       "Pos           0\n",
       "strand        0\n",
       "           ... \n",
       "WH1279      392\n",
       "WH1280      165\n",
       "WH1281     1303\n",
       "WH1283      508\n",
       "WH1284     1077\n",
       "Length: 291, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading of the datasets and understanding the size,the no. of null values and various other elements\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "gt =  pd.read_csv(\"datasets\\Genotype_Data.csv\")\n",
    "pt=pd.read_csv(\"datasets\\Phenotypic_Data.csv\")\n",
    "\n",
    "pt.size\n",
    "gt.size\n",
    "pt.head()\n",
    "gt.head()\n",
    "\n",
    "gt.info()\n",
    "pt.info()\n",
    "gt.isnull().sum()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the useless or no related cols from the dataset\n",
    "col=pt['Genotype']\n",
    "cols_to_drop=['Chrom','Pos','strand','assembly','center','protLSID','assayLSID','panel','QCcode']\n",
    "gt=gt.drop(cols_to_drop,axis=1)\n",
    "gt.to_csv(\"updated_genotype\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNPs</th>\n",
       "      <th>alleles</th>\n",
       "      <th>AAI-W22</th>\n",
       "      <th>AAI-W29</th>\n",
       "      <th>AKAW5080</th>\n",
       "      <th>AKAW5088</th>\n",
       "      <th>AKAW5099</th>\n",
       "      <th>BCW5</th>\n",
       "      <th>BRW3863</th>\n",
       "      <th>BRW3869</th>\n",
       "      <th>...</th>\n",
       "      <th>WH1274</th>\n",
       "      <th>WH1275</th>\n",
       "      <th>WH1276</th>\n",
       "      <th>WH1277</th>\n",
       "      <th>WH1278</th>\n",
       "      <th>WH1279</th>\n",
       "      <th>WH1280</th>\n",
       "      <th>WH1281</th>\n",
       "      <th>WH1283</th>\n",
       "      <th>WH1284</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AX-94381285</td>\n",
       "      <td>C/T</td>\n",
       "      <td>TC</td>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "      <td>TC</td>\n",
       "      <td>CC</td>\n",
       "      <td>...</td>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AX-94383718</td>\n",
       "      <td>A/G</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA</td>\n",
       "      <td>AG</td>\n",
       "      <td>AA</td>\n",
       "      <td>...</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AX-94384181</td>\n",
       "      <td>A/G</td>\n",
       "      <td>AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA</td>\n",
       "      <td>GG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GG</td>\n",
       "      <td>...</td>\n",
       "      <td>GG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>GG</td>\n",
       "      <td>GG</td>\n",
       "      <td>AA</td>\n",
       "      <td>GG</td>\n",
       "      <td>AA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AX-94384966</td>\n",
       "      <td>T/C</td>\n",
       "      <td>CC</td>\n",
       "      <td>TT</td>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "      <td>TT</td>\n",
       "      <td>TT</td>\n",
       "      <td>CC</td>\n",
       "      <td>TT</td>\n",
       "      <td>...</td>\n",
       "      <td>CC</td>\n",
       "      <td>TT</td>\n",
       "      <td>CC</td>\n",
       "      <td>TT</td>\n",
       "      <td>TT</td>\n",
       "      <td>TT</td>\n",
       "      <td>TT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AX-94386458</td>\n",
       "      <td>C/A</td>\n",
       "      <td>CC</td>\n",
       "      <td>AA</td>\n",
       "      <td>AC</td>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "      <td>AA</td>\n",
       "      <td>CC</td>\n",
       "      <td>...</td>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "      <td>AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 282 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SNPs alleles AAI-W22 AAI-W29 AKAW5080 AKAW5088 AKAW5099 BCW5  \\\n",
       "0  AX-94381285     C/T      TC      CC       CC       CC       CC   CC   \n",
       "1  AX-94383718     A/G      AA      AA       AA       AA       AA   AA   \n",
       "2  AX-94384181     A/G      AA     NaN      NaN       AA       AA   GG   \n",
       "3  AX-94384966     T/C      CC      TT       CC       CC       TT   TT   \n",
       "4  AX-94386458     C/A      CC      AA       AC       CC       CC   CC   \n",
       "\n",
       "  BRW3863 BRW3869  ... WH1274 WH1275 WH1276 WH1277 WH1278 WH1279 WH1280  \\\n",
       "0      TC      CC  ...     CC     CC     CC     CC     CC     CC     CC   \n",
       "1      AG      AA  ...     AA     AA     AA     AA     AA     AA     AA   \n",
       "2     NaN      GG  ...     GG    NaN    NaN    NaN     AA     GG     GG   \n",
       "3      CC      TT  ...     CC     TT     CC     TT     TT     TT     TT   \n",
       "4      AA      CC  ...     CC     CC     CC     CC     CC     CC     AA   \n",
       "\n",
       "  WH1281 WH1283 WH1284  \n",
       "0     CC    NaN     CC  \n",
       "1     AA     AA     AA  \n",
       "2     AA     GG     AA  \n",
       "3    NaN     CC     CC  \n",
       "4    NaN     CC    NaN  \n",
       "\n",
       "[5 rows x 282 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SNPs           0\n",
       "alleles        0\n",
       "AAI-W22      395\n",
       "AAI-W29     1155\n",
       "AKAW5080     624\n",
       "            ... \n",
       "WH1279       392\n",
       "WH1280       165\n",
       "WH1281      1303\n",
       "WH1283       508\n",
       "WH1284      1077\n",
       "Length: 282, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(\"updated_genotype\")\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Replacing the null values for given dataset with primary allele\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def replace_nan_with_first_letter(value, alleles):\n",
    "    if pd.isna(value):\n",
    "        letter_before_slash = alleles.split('/')[0]\n",
    "        return letter_before_slash * 2\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "for column in df.columns[1:]:\n",
    "    df[column] = df.apply(lambda row: replace_nan_with_first_letter(row[column], row['alleles']), axis=1)\n",
    "\n",
    "df=df.drop(['alleles'],axis=1)\n",
    "df.to_csv(\"final_genotype\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the other cols from phenotype dataset as we consider only pooled values\n",
    "\n",
    "dropme=[]\n",
    "for i in pt.columns:\n",
    "    if i=='DH_Pooled' or i=='GFD_Pooled' or i=='GNPS_Pooled' or i=='GWPS_Pooled' or i=='PH_Pooled' or i=='GY_Pooled':\n",
    "        continue\n",
    "    else:\n",
    "        dropme.append(i)\n",
    "dropme=dropme[1:]\n",
    "\n",
    "pt=pt.drop(dropme,axis=1)\n",
    "pt.to_csv(\"final_phenotype\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding and replacing the encoded values\n",
    "\n",
    "geno_map={'AA':1,'AT':2,'AG':3,'AC':4,'TT':5,'TG':6,'TC':7,'GG':8,'CG':9,'CC':10}\n",
    "sample_geno=pd.read_csv(\"final_genotype\")\n",
    "df2=pd.DataFrame(sample_geno)\n",
    "\n",
    "for i in df2[1:]:\n",
    "    df2[i]=df2[i].map(geno_map)\n",
    "\n",
    "df2['SNPs']=df['SNPs']\n",
    "df2.head()\n",
    "df2.to_csv(\"fgenotype\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd \n",
    "\n",
    "# seq=\"\"\n",
    "# snps=[]\n",
    "# coms=[]\n",
    "# cm=pd.read_csv(\"final_genotype\")\n",
    "# for i in cm.values:\n",
    "#     for j in i:\n",
    "#         snps.append(j)\n",
    "#         i=i[1:]\n",
    "#         seq+=j\n",
    "#     if(seq not in coms):\n",
    "#         coms.append(seq)\n",
    "#     else:\n",
    "#         snps.remove(snps[len(snps)-1])\n",
    "# print(len(snps))\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging both the dataset based on genotype  \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "fg=pd.read_csv(\"fgenotype\")\n",
    "fp=pd.read_csv(\"final_phenotype\")\n",
    "\n",
    "\n",
    "\n",
    "fg = fg.set_index('SNPs').T.reset_index()\n",
    "\n",
    "fg.columns.name = None\n",
    "fg = fg.rename(columns={'index': 'Genotype'})\n",
    "\n",
    "merged_dataset = pd.merge(fg, fp, on='Genotype')\n",
    "\n",
    "merged_dataset.to_csv(\"mergeds\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5878\n",
      "6084\n",
      "5863\n",
      "5925\n",
      "6052\n",
      "5869\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "# Finding the Coorelation among the snp data and traits(pooled values) and Finding the number of common snps which highly influence the majority data\n",
    "p=[]\n",
    "f=[]\n",
    "import pandas as pd\n",
    "poled=[ 'DH_Pooled','GFD_Pooled' ,'GNPS_Pooled','GWPS_Pooled','PH_Pooled','GY_Pooled']\n",
    "\n",
    "md=pd.read_csv(\"mergeds\")\n",
    "\n",
    "snp_data = md.iloc[:, 1:14790]\n",
    "\n",
    "for i in poled:\n",
    "    gfd_pooled = md[i]\n",
    "    corr_gfd= snp_data.corrwith(gfd_pooled)\n",
    "    snp_corr_df = pd.DataFrame({'SNP': snp_data.columns, 'Correlation': corr_gfd})\n",
    "    snp_corr_df = snp_corr_df.sort_values(by='Correlation', ascending=False)\n",
    "\n",
    "    k=[]\n",
    "\n",
    "    for i ,j in  enumerate(snp_corr_df['Correlation']):\n",
    "        if(j>0):\n",
    "            k.append(snp_corr_df['SNP'].iloc[i])\n",
    "    k = k[0:len(k)*4//5]\n",
    "    p.append(k)\n",
    "\n",
    "\n",
    "for i in p:\n",
    "    print(len(i))\n",
    "f = p\n",
    "list1 = f[0]\n",
    "list2 = f[1]\n",
    "list3 = f[2]\n",
    "list4 = f[3]\n",
    "list5 = f[4]\n",
    "list6 = f[5]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "set1 = set(list1)\n",
    "set2 = set(list2)\n",
    "set3 = set(list3)\n",
    "set4 = set(list4)\n",
    "set5 = set(list5)\n",
    "set6 = set(list6)\n",
    "# Find the common elements\n",
    "common_elements = set1.intersection(set2,set3,set4,set5,set6)\n",
    "#common_elements = set(common_elements).intersection(set3)\n",
    "\n",
    "# Convert the result back to a list (if needed)\n",
    "common_elements_list = list(common_elements)\n",
    "\n",
    "print(len(common_elements_list))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the non related snps from the dataset\n",
    "dp=[]\n",
    "for i in sorted(md.columns[1:]):\n",
    "    if i not in common_elements_list:\n",
    "        dp.append(i)\n",
    "\n",
    "poled=[ 'DH_Pooled','GFD_Pooled' ,'GNPS_Pooled','GWPS_Pooled','PH_Pooled','GY_Pooled']\n",
    "for i in poled:\n",
    "    dp.remove(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the Final dataset\n",
    "\n",
    "md1=pd.read_csv(\"mergeds\")\n",
    "md1=md1.drop(columns=dp)\n",
    "md1.to_csv(\"pheno_geno\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(md1['Genotype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Building the DL model ->(FNN model) and Predicting the values\n",
    "\n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# # Load your dataset\n",
    "# # Assuming df contains your data\n",
    "# df = md1\n",
    "\n",
    "# # X should be the genetic sequences\n",
    "# # y should be the trait values (DH_Pooled, GFD_Pooled, GNPS_Pooled, GWPS_Pooled, PH_Pooled, GY_Pooled)\n",
    "# X = df.iloc[:, 1:25]  # Assuming the DNA sequences start from the second column\n",
    "\n",
    "# # Extract the trait values\n",
    "# y = df[['DH_Pooled', 'GFD_Pooled', 'GNPS_Pooled', 'GWPS_Pooled', 'PH_Pooled', 'GY_Pooled']]\n",
    "\n",
    "# # Split the data into training and test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Standardize input features and trait values separately\n",
    "# scaler_X = MinMaxScaler()\n",
    "# scaler_y = MinMaxScaler()\n",
    "\n",
    "# X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "# X_test_scaled = scaler_X.transform(X_test)\n",
    "# y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "# y_test_scaled = scaler_y.transform(y_test)\n",
    "\n",
    "# # Build the FNN model\n",
    "# model = keras.Sequential([\n",
    "#     keras.layers.Input(shape=(X_train.shape[1],)),\n",
    "#     keras.layers.Dense(128, activation='elu'),\n",
    "#     keras.layers.Dense(64, activation='elu'),\n",
    "#     keras.layers.Dense(32, activation='elu'),\n",
    "#     keras.layers.Dense(6, activation='sigmoid')  # Use sigmoid activation for output layer for values between 0 and 1\n",
    "# ])\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(X_train_scaled, y_train_scaled, epochs=50, batch_size=10, validation_split=0.2)\n",
    "\n",
    "# # Evaluate the model on the test set\n",
    "# y_pred_scaled = model.predict(X_test_scaled)\n",
    "# mae = mean_squared_error(y_test_scaled, y_pred_scaled)\n",
    "\n",
    "# # Generate and predict a new sequence\n",
    "# new_sequence_1 = np.array([1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,1,2,3,4,4]).reshape(1, -1)  # Reshape to match input shape\n",
    "# scaled_new_sequence = scaler_X.transform(new_sequence_1)\n",
    "# predictions_scaled = model.predict(scaled_new_sequence)\n",
    "\n",
    "# # Inverse transform the scaled predictions to get the original scale\n",
    "# predictions = scaler_y.inverse_transform(predictions_scaled)\n",
    "\n",
    "# print(\"Root Mean Squared Error (RMSE):\", np.sqrt(mae))\n",
    "# print(\"Predictions:\", predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (MSE): 0.12774364993275047\n",
      "Predictions: [[ 83.92294117  42.7794525   48.03183817   2.23483025  95.35428258\n",
      "  425.35357883]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import *\n",
    "\n",
    "# Load your dataset\n",
    "# Assuming df contains your data\n",
    "df = md1\n",
    "\n",
    "# X should be the genetic sequences\n",
    "# y should be the trait values (DH_Pooled, GFD_Pooled, GNPS_Pooled, GWPS_Pooled, PH_Pooled, GY_Pooled)\n",
    "X = df.iloc[:, 1:25]  # Assuming the DNA sequences start from the second column\n",
    "\n",
    "# Extract the trait values\n",
    "y = df[['DH_Pooled', 'GFD_Pooled', 'GNPS_Pooled', 'GWPS_Pooled', 'PH_Pooled', 'GY_Pooled']]\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize input features and trait values separately (using the same scalers)\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "y_test_scaled = scaler_y.transform(y_test)\n",
    "\n",
    "# Build and train a Random Forest Regressor model\n",
    "random_forest_model = RandomForestRegressor(n_estimators=100, random_state=42)  # You can adjust hyperparameters\n",
    "random_forest_model.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_scaled = random_forest_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mae = mean_squared_error(y_test_scaled, y_pred_scaled)\n",
    "\n",
    "# Generate and predict a new sequence\n",
    "new_sequence_1 = np.array([1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,1,2,3,4,4]).reshape(1, -1)  # Reshape to match input shape\n",
    "scaled_new_sequence = scaler_X.transform(new_sequence_1)\n",
    "predictions_scaled = random_forest_model.predict(scaled_new_sequence)\n",
    "\n",
    "# Inverse transform the scaled predictions to get the original scale\n",
    "predictions = scaler_y.inverse_transform(predictions_scaled)\n",
    "\n",
    "\n",
    "print(\"Root Mean Squared Error (MSE):\", np.sqrt(mae))\n",
    "print(\"Predictions:\", predictions)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "\n",
    "# # Save the Random Forest model\n",
    "# joblib.dump(random_forest_model, 'random_forest_model.pkl')\n",
    "\n",
    "# # Save the scalers\n",
    "# joblib.dump(scaler_X, 'scaler_X.pkl')\n",
    "# joblib.dump(scaler_y, 'scaler_y.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# # Load your Keras model\n",
    "# model = tf.keras.models.load_model('Final_Model')\n",
    "\n",
    "# # Convert the Keras model to TFLite\n",
    "# converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# tflite_model = converter.convert()\n",
    "\n",
    "# # Save the TFLite model to a file\n",
    "# with open('TFLYT\\FNN_quant.tflite', 'wb') as f:\n",
    "#     f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# gg=pd.read_csv(\"datasets\\Genotypic_Data.csv\")\n",
    "# kk=pd.read_csv(\"pheno_geno\")\n",
    "\n",
    "# dp=[]\n",
    "# for i in kk.columns:\n",
    "#     dp.append(i)\n",
    "\n",
    "# dp=dp[1:]\n",
    "# dp=dp[:24]\n",
    "\n",
    "# snps_series = pd.Series(df['SNPs'])\n",
    "# df=gg\n",
    "# pos_values = df[df['SNPs'].isin(dp)]['Pos']\n",
    "\n",
    "\n",
    "\n",
    "# print(pos_values.tolist())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
